{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dC3nTnLyZNnv"
      },
      "source": [
        "# AfterWork Data Science: Getting Started with NLP Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enxDwtXPZTpT"
      },
      "source": [
        "### Prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dz7plWFhaQ9R"
      },
      "outputs": [],
      "source": [
        "# Importing the required libraries\n",
        "# ---\n",
        "# \n",
        "import pandas as pd # library for data manipulation\n",
        "import numpy as np  # librariy for scientific computations\n",
        "import re           # regex library to perform text preprocessing\n",
        "import string       # library to work with strings\n",
        "import nltk         # library for natural language processing\n",
        "import scipy        # scientific conputing "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85tygFqJZ0Xw"
      },
      "source": [
        "### 1. Importing our Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_d2EpfjafP3"
      },
      "outputs": [],
      "source": [
        "# Question: Given a new tweets, create a sentiment analysis model that will \n",
        "# predict whether a tweet will contain positive or negative sentiment.\n",
        "# ---\n",
        "# Dataset url = https://bit.ly/31kqByD \n",
        "# ---\n",
        "#\n",
        "data = pd.read_csv('https://bit.ly/31kqByD', encoding='latin-1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dpe7vKQreIIv",
        "outputId": "ee4a807f-f3d9-4a3f-901c-2a97b3e9b392"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "      <th>1467810369</th>\n",
              "      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n",
              "      <th>NO_QUERY</th>\n",
              "      <th>_TheSpecialOne_</th>\n",
              "      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>346508</td>\n",
              "      <td>0</td>\n",
              "      <td>2016177685</td>\n",
              "      <td>Wed Jun 03 06:18:50 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>UriGrey</td>\n",
              "      <td>Obama forges his Muslim alliance against the c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>883537</td>\n",
              "      <td>4</td>\n",
              "      <td>1686152287</td>\n",
              "      <td>Sun May 03 04:02:08 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>MariesolW</td>\n",
              "      <td>Had the most spectacular prom ever  but now my...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>764173</td>\n",
              "      <td>0</td>\n",
              "      <td>2298725623</td>\n",
              "      <td>Tue Jun 23 12:02:12 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ColleenBurns</td>\n",
              "      <td>I am overwhelmed today  taking a moment to eat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>638701</td>\n",
              "      <td>0</td>\n",
              "      <td>2234530495</td>\n",
              "      <td>Thu Jun 18 23:13:54 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>queenarchy</td>\n",
              "      <td>@lindork Tres sad. I was totally a Max fan.  #...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>664821</td>\n",
              "      <td>0</td>\n",
              "      <td>2244623416</td>\n",
              "      <td>Fri Jun 19 14:59:46 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>reinventingjess</td>\n",
              "      <td>Crap, I was counting down the hours until my d...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  \\\n",
              "0      346508  0  2016177685  Wed Jun 03 06:18:50 PDT 2009  NO_QUERY   \n",
              "1      883537  4  1686152287  Sun May 03 04:02:08 PDT 2009  NO_QUERY   \n",
              "2      764173  0  2298725623  Tue Jun 23 12:02:12 PDT 2009  NO_QUERY   \n",
              "3      638701  0  2234530495  Thu Jun 18 23:13:54 PDT 2009  NO_QUERY   \n",
              "4      664821  0  2244623416  Fri Jun 19 14:59:46 PDT 2009  NO_QUERY   \n",
              "\n",
              "   _TheSpecialOne_  \\\n",
              "0          UriGrey   \n",
              "1        MariesolW   \n",
              "2     ColleenBurns   \n",
              "3       queenarchy   \n",
              "4  reinventingjess   \n",
              "\n",
              "  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
              "0  Obama forges his Muslim alliance against the c...                                                                   \n",
              "1  Had the most spectacular prom ever  but now my...                                                                   \n",
              "2  I am overwhelmed today  taking a moment to eat...                                                                   \n",
              "3  @lindork Tres sad. I was totally a Max fan.  #...                                                                   \n",
              "4  Crap, I was counting down the hours until my d...                                                                   "
            ]
          },
          "execution_count": 238,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = data.copy()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96Uz3PxJZ6E7"
      },
      "source": [
        "### 2. Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tv_yGMvFbZtL",
        "outputId": "58f06293-c898-477c-a185-f08fa806efc7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 7)"
            ]
          },
          "execution_count": 239,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# We can determine the size of our dataset\n",
        "# ---\n",
        "#\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDtEQCn6oAwJ"
      },
      "source": [
        "Seems this dataset will need some data cleaning i.e. columns. We also don't need some columns to perform create our model. We will drop those columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvsnLPXTZ8P0"
      },
      "source": [
        "### 3. Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlHYpKxfHRJ4"
      },
      "source": [
        "#### Basic Data Cleaning Techniques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hpqmVDWbfcM",
        "outputId": "9691407f-1f3b-49b3-baf0-509d9270d36a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "      <th>t_id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>query</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>346508</td>\n",
              "      <td>0</td>\n",
              "      <td>2016177685</td>\n",
              "      <td>Wed Jun 03 06:18:50 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>UriGrey</td>\n",
              "      <td>Obama forges his Muslim alliance against the c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>883537</td>\n",
              "      <td>4</td>\n",
              "      <td>1686152287</td>\n",
              "      <td>Sun May 03 04:02:08 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>MariesolW</td>\n",
              "      <td>Had the most spectacular prom ever  but now my...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>764173</td>\n",
              "      <td>0</td>\n",
              "      <td>2298725623</td>\n",
              "      <td>Tue Jun 23 12:02:12 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ColleenBurns</td>\n",
              "      <td>I am overwhelmed today  taking a moment to eat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>638701</td>\n",
              "      <td>0</td>\n",
              "      <td>2234530495</td>\n",
              "      <td>Thu Jun 18 23:13:54 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>queenarchy</td>\n",
              "      <td>@lindork Tres sad. I was totally a Max fan.  #...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>664821</td>\n",
              "      <td>0</td>\n",
              "      <td>2244623416</td>\n",
              "      <td>Fri Jun 19 14:59:46 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>reinventingjess</td>\n",
              "      <td>Crap, I was counting down the hours until my d...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id  target        t_id                    created_at     query  \\\n",
              "0  346508       0  2016177685  Wed Jun 03 06:18:50 PDT 2009  NO_QUERY   \n",
              "1  883537       4  1686152287  Sun May 03 04:02:08 PDT 2009  NO_QUERY   \n",
              "2  764173       0  2298725623  Tue Jun 23 12:02:12 PDT 2009  NO_QUERY   \n",
              "3  638701       0  2234530495  Thu Jun 18 23:13:54 PDT 2009  NO_QUERY   \n",
              "4  664821       0  2244623416  Fri Jun 19 14:59:46 PDT 2009  NO_QUERY   \n",
              "\n",
              "              user                                               text  \n",
              "0          UriGrey  Obama forges his Muslim alliance against the c...  \n",
              "1        MariesolW  Had the most spectacular prom ever  but now my...  \n",
              "2     ColleenBurns  I am overwhelmed today  taking a moment to eat...  \n",
              "3       queenarchy  @lindork Tres sad. I was totally a Max fan.  #...  \n",
              "4  reinventingjess  Crap, I was counting down the hours until my d...  "
            ]
          },
          "execution_count": 240,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# We rename the columns for ease of referencing our columns later on\n",
        "# ---\n",
        "#\n",
        "df.columns = ['id', 'target', 't_id', 'created_at', 'query', 'user', 'text']\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HSGdDX3bjUB",
        "outputId": "29166945-a79a-47df-fec5-3ab2403d4b31"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Obama forges his Muslim alliance against the c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>Had the most spectacular prom ever  but now my...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>I am overwhelmed today  taking a moment to eat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>@lindork Tres sad. I was totally a Max fan.  #...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Crap, I was counting down the hours until my d...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   target                                               text\n",
              "0       0  Obama forges his Muslim alliance against the c...\n",
              "1       4  Had the most spectacular prom ever  but now my...\n",
              "2       0  I am overwhelmed today  taking a moment to eat...\n",
              "3       0  @lindork Tres sad. I was totally a Max fan.  #...\n",
              "4       0  Crap, I was counting down the hours until my d..."
            ]
          },
          "execution_count": 241,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# We retain the relevant columns by dropping the columns we don't need \n",
        "# for creating a sentiment analysis model. \n",
        "# ---\n",
        "#\n",
        "df = df.drop(['id', 't_id', 'created_at', 'query', 'user'], axis = 1)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgnEEnresgJl",
        "outputId": "8f75c4a2-38fb-4cb7-8870-22dc6536cd07"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    5067\n",
              "4    4933\n",
              "Name: target, dtype: int64"
            ]
          },
          "execution_count": 242,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Understanding the distribution of target\n",
        "# ---\n",
        "#\n",
        "df.target.value_counts() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8riNiGfupWL",
        "outputId": "dd8f0ef5-6268-4bae-9cc6-31947b40bcbb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "target     int64\n",
              "text      object\n",
              "dtype: object"
            ]
          },
          "execution_count": 243,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's determine whether our columns have the right data types\n",
        "# ---\n",
        "#\n",
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ns54XoFrVcLp",
        "outputId": "7842afb8-ed92-435b-d3d0-6fd44bfccbb8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 4], dtype=int64)"
            ]
          },
          "execution_count": 244,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# What values are in our target variable?\n",
        "# ---\n",
        "#\n",
        "df.target.unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmYkmFOBVtMC"
      },
      "source": [
        "These are the two classes to which each document (text) belongs. The target value 0 means a text with a negative sentiment, while that of 4 means a text with a positive sentiment. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6JoJc4Nvz1S",
        "outputId": "1a955ddb-d911-4e18-b148-8c79fefc4f71"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "target    0\n",
              "text      0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 245,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's check for missing values \n",
        "# ---\n",
        "# \n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxpcyoUfoy9s"
      },
      "source": [
        "We don't have any missing values, so we are good to go."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BdB9m4_yK-1"
      },
      "source": [
        "#### Text Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8BW53FUm41_",
        "outputId": "5d05613a-d55b-4192-b173-c5fb19e1bca6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Obama forges his Muslim alliance against the c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Had the most spectacular prom ever  but now my...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I am overwhelmed today  taking a moment to eat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@lindork Tres sad. I was totally a Max fan.  #...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Crap, I was counting down the hours until my d...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  Obama forges his Muslim alliance against the c...\n",
              "1  Had the most spectacular prom ever  but now my...\n",
              "2  I am overwhelmed today  taking a moment to eat...\n",
              "3  @lindork Tres sad. I was totally a Max fan.  #...\n",
              "4  Crap, I was counting down the hours until my d..."
            ]
          },
          "execution_count": 246,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Text Cleaning: Removing all urls/links\n",
        "# ---\n",
        "# \n",
        "df['text'] =  df['text'].apply(lambda x: re.sub(r'http\\S+|www\\S+|https\\S+','', str(x)))\n",
        "df[['text']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UR9gL4v8m9mV",
        "outputId": "0db6e7a8-fc8b-4c34-ba01-05d9a08e064b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Obama forges his Muslim alliance against the c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Had the most spectacular prom ever  but now my...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I am overwhelmed today  taking a moment to eat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lindork Tres sad. I was totally a Max fan.  SY...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Crap, I was counting down the hours until my d...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  Obama forges his Muslim alliance against the c...\n",
              "1  Had the most spectacular prom ever  but now my...\n",
              "2  I am overwhelmed today  taking a moment to eat...\n",
              "3  lindork Tres sad. I was totally a Max fan.  SY...\n",
              "4  Crap, I was counting down the hours until my d..."
            ]
          },
          "execution_count": 247,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Text Cleaning: Removing @ and # characters or replace them with space\n",
        "# ---\n",
        "df['text'] =  df['text'].apply(lambda x: re.sub(r'@|#','', str(x)))\n",
        "df[['text']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cTS7iaXdAQz",
        "outputId": "22203420-1e1e-481c-8016-fa0381b18eaa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>obama forges his muslim alliance against the c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>had the most spectacular prom ever  but now my...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i am overwhelmed today  taking a moment to eat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lindork tres sad. i was totally a max fan.  sy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>crap, i was counting down the hours until my d...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  obama forges his muslim alliance against the c...\n",
              "1  had the most spectacular prom ever  but now my...\n",
              "2  i am overwhelmed today  taking a moment to eat...\n",
              "3  lindork tres sad. i was totally a max fan.  sy...\n",
              "4  crap, i was counting down the hours until my d..."
            ]
          },
          "execution_count": 248,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Text Cleaning: Conversion to lowercase\n",
        "# ---\n",
        "df['text'] =  df['text'].apply(str.lower)\n",
        "df[['text']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKO79Jh_wWD_",
        "outputId": "06f8f4b4-dfbe-4211-d156-07c51208470f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wordninja in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (2.0.0)\n",
            "Requirement already satisfied: textblob in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (0.15.3)\n",
            "Requirement already satisfied: nltk>=3.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from textblob) (3.5)\n",
            "Requirement already satisfied: regex in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (2020.10.15)\n",
            "Requirement already satisfied: joblib in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (0.17.0)\n",
            "Requirement already satisfied: tqdm in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (4.50.2)\n",
            "Requirement already satisfied: click in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "# Installing wordnija and textblob\n",
        "# ---\n",
        "#\n",
        "!pip install wordninja\n",
        "!pip install textblob\n",
        "\n",
        "# Importing those libraries\n",
        "# ---\n",
        "#\n",
        "import wordninja\n",
        "import textblob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8M9zulureII2",
        "outputId": "a19a2f71-356e-4d26-95c3-463c1b5f9878"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>obama forges his muslim alliance against the c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>had the most spectacular prom ever  but now my...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>i am overwhelmed today  taking a moment to eat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>lindork tres sad. i was totally a max fan.  sy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>crap, i was counting down the hours until my d...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   target                                               text\n",
              "0       0  obama forges his muslim alliance against the c...\n",
              "1       4  had the most spectacular prom ever  but now my...\n",
              "2       0  i am overwhelmed today  taking a moment to eat...\n",
              "3       0  lindork tres sad. i was totally a max fan.  sy...\n",
              "4       0  crap, i was counting down the hours until my d..."
            ]
          },
          "execution_count": 250,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edYEOU8Tc6sJ",
        "outputId": "e5388f0f-a0e0-47f0-9190-6539db627462"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>obama forges his muslim alliance against the c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>had the most spectacular prom ever but now my ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i am overwhelmed today taking a moment to eat ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lindork tres sad i was totally a max fan sytycd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>crap i was counting down the hours until my da...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  obama forges his muslim alliance against the c...\n",
              "1  had the most spectacular prom ever but now my ...\n",
              "2  i am overwhelmed today taking a moment to eat ...\n",
              "3    lindork tres sad i was totally a max fan sytycd\n",
              "4  crap i was counting down the hours until my da..."
            ]
          },
          "execution_count": 251,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Text Cleaning: Removing punctuation characters\n",
        "# ---\n",
        "df['text'] =  df['text'].apply(lambda x: re.sub(r'\\W+',' ', str(x)))\n",
        "df[['text']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxVb9-dJ9zN5",
        "outputId": "c386c782-8a2c-43b9-b0ea-e632d6deb2cf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[obama forges his muslim alliance against the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[had the most spectacular prom ever but now my...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[i am overwhelmed today taking a moment to eat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[lindork tres sad i was totally a max fan sytycd]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[crap i was counting down the hours until my d...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  [obama forges his muslim alliance against the ...\n",
              "1  [had the most spectacular prom ever but now my...\n",
              "2  [i am overwhelmed today taking a moment to eat...\n",
              "3  [lindork tres sad i was totally a max fan sytycd]\n",
              "4  [crap i was counting down the hours until my d..."
            ]
          },
          "execution_count": 252,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Text Cleaning: Removing stop words\n",
        "# ---\n",
        "def remove_stopword(txt):\n",
        "    stopwords = nltk.corpus.stopwords.words(\"english\")\n",
        "    txt = txt.split(\".\")\n",
        "    txt = [i for i in txt if i not in stopwords]\n",
        "    return txt\n",
        "\n",
        "df['text'] =  df['text'].apply(remove_stopword)\n",
        "df[['text']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37RyhNK-q6Df",
        "outputId": "6697be42-3c7a-4b7f-fd4a-b2ded0cba6cb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>obama forge his muslim alliance against the ci...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>had the most spectacular prom ever but now my ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i am overwhelmed today taking a moment to eat ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lindork tres sad i wa totally a max fan sytycd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>crap i wa counting down the hour until my dad ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  obama forge his muslim alliance against the ci...\n",
              "1  had the most spectacular prom ever but now my ...\n",
              "2  i am overwhelmed today taking a moment to eat ...\n",
              "3     lindork tres sad i wa totally a max fan sytycd\n",
              "4  crap i wa counting down the hour until my dad ..."
            ]
          },
          "execution_count": 253,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Text Cleaning: Lemmatization\n",
        "# ---\n",
        "def lemmatize(txt):\n",
        "    txt = txt[0].split(\" \")\n",
        "    lemma = nltk.stem.WordNetLemmatizer()\n",
        "    txt = [lemma.lemmatize(i) for i in txt]\n",
        "    txt = \" \".join(txt)\n",
        "    return txt\n",
        "# For lemmatization, we will need to download wordnet\n",
        "#\n",
        "nltk.download(\"wordnet\")\n",
        "\n",
        "# Lemmatizing our text\n",
        "# ---\n",
        "#\n",
        "df['text'] =  df['text'].apply(lemmatize)\n",
        "df[['text']].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-t8mVoSYIAAy"
      },
      "source": [
        "We won't remove numerics because we could loose meaning of our text if we lost the numerics. We could also further prepare our text by performing spelling correction but this is a resource intensive process that we will skip for now."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ve5fMuCicKkt"
      },
      "source": [
        "#### Feature Engineering Techniques "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFwaX_bucVar",
        "outputId": "38616dd4-da84-4d44-acf7-a58b498112d5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>text_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>obama forge his muslim alliance against the ci...</td>\n",
              "      <td>104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>had the most spectacular prom ever but now my ...</td>\n",
              "      <td>127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>i am overwhelmed today taking a moment to eat ...</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>lindork tres sad i wa totally a max fan sytycd</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>crap i wa counting down the hour until my dad ...</td>\n",
              "      <td>132</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   target                                               text  text_len\n",
              "0       0  obama forge his muslim alliance against the ci...       104\n",
              "1       4  had the most spectacular prom ever but now my ...       127\n",
              "2       0  i am overwhelmed today taking a moment to eat ...        55\n",
              "3       0     lindork tres sad i wa totally a max fan sytycd        46\n",
              "4       0  crap i wa counting down the hour until my dad ...       132"
            ]
          },
          "execution_count": 254,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Feature Construction: Length of tweet\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "#\n",
        "\n",
        "df['text_len'] =  df['text'].apply(len)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WE70M5mYceto",
        "outputId": "17bbc0c9-a4b1-45a4-e692-45826f36d88c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>text_len</th>\n",
              "      <th>words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>obama forge his muslim alliance against the ci...</td>\n",
              "      <td>104</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>had the most spectacular prom ever but now my ...</td>\n",
              "      <td>127</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>i am overwhelmed today taking a moment to eat ...</td>\n",
              "      <td>55</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>lindork tres sad i wa totally a max fan sytycd</td>\n",
              "      <td>46</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>crap i wa counting down the hour until my dad ...</td>\n",
              "      <td>132</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   target                                               text  text_len  words\n",
              "0       0  obama forge his muslim alliance against the ci...       104     22\n",
              "1       4  had the most spectacular prom ever but now my ...       127     25\n",
              "2       0  i am overwhelmed today taking a moment to eat ...        55     12\n",
              "3       0     lindork tres sad i wa totally a max fan sytycd        46     10\n",
              "4       0  crap i wa counting down the hour until my dad ...       132     30"
            ]
          },
          "execution_count": 255,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Feature Construction: Word count \n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "# \n",
        "def find_count(txt):\n",
        "    txt = txt.split(\" \")\n",
        "    return len(txt)\n",
        "df['words'] =  df['text'].apply(find_count)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yjOYYC4cfji",
        "outputId": "38654f5a-fff2-415a-9d19-20af9358ecc3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>text_len</th>\n",
              "      <th>words</th>\n",
              "      <th>density</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>obama forge his muslim alliance against the ci...</td>\n",
              "      <td>104</td>\n",
              "      <td>22</td>\n",
              "      <td>0.211538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>had the most spectacular prom ever but now my ...</td>\n",
              "      <td>127</td>\n",
              "      <td>25</td>\n",
              "      <td>0.196850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>i am overwhelmed today taking a moment to eat ...</td>\n",
              "      <td>55</td>\n",
              "      <td>12</td>\n",
              "      <td>0.218182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>lindork tres sad i wa totally a max fan sytycd</td>\n",
              "      <td>46</td>\n",
              "      <td>10</td>\n",
              "      <td>0.217391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>crap i wa counting down the hour until my dad ...</td>\n",
              "      <td>132</td>\n",
              "      <td>30</td>\n",
              "      <td>0.227273</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   target                                               text  text_len  words  \\\n",
              "0       0  obama forge his muslim alliance against the ci...       104     22   \n",
              "1       4  had the most spectacular prom ever but now my ...       127     25   \n",
              "2       0  i am overwhelmed today taking a moment to eat ...        55     12   \n",
              "3       0     lindork tres sad i wa totally a max fan sytycd        46     10   \n",
              "4       0  crap i wa counting down the hour until my dad ...       132     30   \n",
              "\n",
              "    density  \n",
              "0  0.211538  \n",
              "1  0.196850  \n",
              "2  0.218182  \n",
              "3  0.217391  \n",
              "4  0.227273  "
            ]
          },
          "execution_count": 256,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Feature Construction: Word density (Average no. of words / tweet)\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "#\n",
        "df[\"density\"] = df.words/df.text_len\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoSoEEctcgRq"
      },
      "outputs": [],
      "source": [
        "# Feature Construction: Noun count\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "#\n",
        "# First, we will download the punkt and the averaged_perceptron_tagger into our notebook environment. \n",
        "# which will allow us to find the part of speech tags.\n",
        "# ---\n",
        "#\n",
        "pos_dic = {\n",
        "    'noun' : ['NN','NNS','NNP','NNPS'],\n",
        "    'pron' : ['PRP','PRP$','WP','WP$'],\n",
        "    'verb' : ['VB','VBD','VBG','VBN','VBP','VBZ'],\n",
        "    'adj' :  ['JJ','JJR','JJS'],\n",
        "    'adv' : ['RB','RBR','RBS','WRB']\n",
        "}\n",
        "\n",
        "# We create the function to check and get the part of speech tag count of a words in a given sentence\n",
        "def pos_check(x, flag=\"noun\"):\n",
        "    cnt = 0\n",
        "    try:\n",
        "        wiki = TextBlob(x)\n",
        "        for tup in wiki.tags:\n",
        "            ppo = list(tup)[1]\n",
        "            if ppo in pos_dic[flag]:\n",
        "                cnt += 1\n",
        "    except:\n",
        "        pass\n",
        "    return cnt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxzVY6q60V1X",
        "outputId": "f805b5ae-869c-4c78-ec22-2d63ca21e1b3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>text_len</th>\n",
              "      <th>words</th>\n",
              "      <th>density</th>\n",
              "      <th>noun</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>obama forge his muslim alliance against the ci...</td>\n",
              "      <td>104</td>\n",
              "      <td>22</td>\n",
              "      <td>0.211538</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>had the most spectacular prom ever but now my ...</td>\n",
              "      <td>127</td>\n",
              "      <td>25</td>\n",
              "      <td>0.196850</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>i am overwhelmed today taking a moment to eat ...</td>\n",
              "      <td>55</td>\n",
              "      <td>12</td>\n",
              "      <td>0.218182</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>lindork tres sad i wa totally a max fan sytycd</td>\n",
              "      <td>46</td>\n",
              "      <td>10</td>\n",
              "      <td>0.217391</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>crap i wa counting down the hour until my dad ...</td>\n",
              "      <td>132</td>\n",
              "      <td>30</td>\n",
              "      <td>0.227273</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   target                                               text  text_len  words  \\\n",
              "0       0  obama forge his muslim alliance against the ci...       104     22   \n",
              "1       4  had the most spectacular prom ever but now my ...       127     25   \n",
              "2       0  i am overwhelmed today taking a moment to eat ...        55     12   \n",
              "3       0     lindork tres sad i wa totally a max fan sytycd        46     10   \n",
              "4       0  crap i wa counting down the hour until my dad ...       132     30   \n",
              "\n",
              "    density  noun  \n",
              "0  0.211538     0  \n",
              "1  0.196850     0  \n",
              "2  0.218182     0  \n",
              "3  0.217391     0  \n",
              "4  0.227273     0  "
            ]
          },
          "execution_count": 258,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Noun Count\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "#\n",
        "df[\"noun\"]=df.text.apply(pos_check)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0hHkQb_cfNI"
      },
      "outputs": [],
      "source": [
        "# Feature Construction: Verb count\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "#\n",
        "def pos_check(x, flag=\"verb\"):\n",
        "    cnt = 0\n",
        "    try:\n",
        "        wiki = TextBlob(x)\n",
        "        for tup in wiki.tags:\n",
        "            ppo = list(tup)[1]\n",
        "            if ppo in pos_dic[flag]:\n",
        "                cnt += 1\n",
        "    except:\n",
        "        pass\n",
        "    return cnt\n",
        "df[\"verb\"]=df.text.apply(pos_check)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7foa2jELcdc7"
      },
      "outputs": [],
      "source": [
        "# Feature Construction: Adjective count / Tweet\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "#\n",
        "def pos_check(x, flag=\"adj\"):\n",
        "    cnt = 0\n",
        "    try:\n",
        "        wiki = TextBlob(x)\n",
        "        for tup in wiki.tags:\n",
        "            ppo = list(tup)[1]\n",
        "            if ppo in pos_dic[flag]:\n",
        "                cnt += 1\n",
        "    except:\n",
        "        pass\n",
        "    return cnt\n",
        "df[\"adj\"]=df.text.apply(pos_check)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smNLu-KJcdMT"
      },
      "outputs": [],
      "source": [
        "# Feature Construction: Adverb count / Tweet\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "#\n",
        "def pos_check(x, flag=\"adv\"):\n",
        "    cnt = 0\n",
        "    try:\n",
        "        wiki = TextBlob(x)\n",
        "        for tup in wiki.tags:\n",
        "            ppo = list(tup)[1]\n",
        "            if ppo in pos_dic[flag]:\n",
        "                cnt += 1\n",
        "    except:\n",
        "        pass\n",
        "    return cnt\n",
        "df[\"adv\"]=df.text.apply(pos_check)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRjeP3R2dDWA"
      },
      "outputs": [],
      "source": [
        "# Feature Construction: Pronoun \n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "#\n",
        "def pos_check(x, flag=\"pron\"):\n",
        "    cnt = 0\n",
        "    try:\n",
        "        wiki = TextBlob(x)\n",
        "        for tup in wiki.tags:\n",
        "            ppo = list(tup)[1]\n",
        "            if ppo in pos_dic[flag]:\n",
        "                cnt += 1\n",
        "    except:\n",
        "        pass\n",
        "    return cnt\n",
        "df[\"pron\"]=df.text.apply(pos_check)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1ab-9bOdEAT",
        "outputId": "c6e75d70-c367-4827-8658-a0dc80aaa2ec"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>text_len</th>\n",
              "      <th>words</th>\n",
              "      <th>density</th>\n",
              "      <th>noun</th>\n",
              "      <th>verb</th>\n",
              "      <th>adj</th>\n",
              "      <th>adv</th>\n",
              "      <th>pron</th>\n",
              "      <th>subjecttivity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>obama forge his muslim alliance against the ci...</td>\n",
              "      <td>104</td>\n",
              "      <td>22</td>\n",
              "      <td>0.211538</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>had the most spectacular prom ever but now my ...</td>\n",
              "      <td>127</td>\n",
              "      <td>25</td>\n",
              "      <td>0.196850</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.762500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>i am overwhelmed today taking a moment to eat ...</td>\n",
              "      <td>55</td>\n",
              "      <td>12</td>\n",
              "      <td>0.218182</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>lindork tres sad i wa totally a max fan sytycd</td>\n",
              "      <td>46</td>\n",
              "      <td>10</td>\n",
              "      <td>0.217391</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.875000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>crap i wa counting down the hour until my dad ...</td>\n",
              "      <td>132</td>\n",
              "      <td>30</td>\n",
              "      <td>0.227273</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.474074</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   target                                               text  text_len  words  \\\n",
              "0       0  obama forge his muslim alliance against the ci...       104     22   \n",
              "1       4  had the most spectacular prom ever but now my ...       127     25   \n",
              "2       0  i am overwhelmed today taking a moment to eat ...        55     12   \n",
              "3       0     lindork tres sad i wa totally a max fan sytycd        46     10   \n",
              "4       0  crap i wa counting down the hour until my dad ...       132     30   \n",
              "\n",
              "    density  noun  verb  adj  adv  pron  subjecttivity  \n",
              "0  0.211538     0     0    0    0     0       0.900000  \n",
              "1  0.196850     0     0    0    0     0       0.762500  \n",
              "2  0.218182     0     0    0    0     0       0.000000  \n",
              "3  0.217391     0     0    0    0     0       0.875000  \n",
              "4  0.227273     0     0    0    0     0       0.474074  "
            ]
          },
          "execution_count": 263,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Feature Construction: Subjectivity\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "# \n",
        "\n",
        "# Function to calculate subjectiveity and polarity\n",
        "def get_subjectivity(text):\n",
        "    return textblob.TextBlob(text).sentiment.subjectivity\n",
        "\n",
        "df[\"subjecttivity\"]=df.text.apply(get_subjectivity)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEt889AByeHq",
        "outputId": "1871a954-06dd-40e6-b35f-aedc0845ebac"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>text_len</th>\n",
              "      <th>words</th>\n",
              "      <th>density</th>\n",
              "      <th>noun</th>\n",
              "      <th>verb</th>\n",
              "      <th>adj</th>\n",
              "      <th>adv</th>\n",
              "      <th>pron</th>\n",
              "      <th>subjecttivity</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>obama forge his muslim alliance against the ci...</td>\n",
              "      <td>104</td>\n",
              "      <td>22</td>\n",
              "      <td>0.211538</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>had the most spectacular prom ever but now my ...</td>\n",
              "      <td>127</td>\n",
              "      <td>25</td>\n",
              "      <td>0.196850</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.762500</td>\n",
              "      <td>0.612500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>i am overwhelmed today taking a moment to eat ...</td>\n",
              "      <td>55</td>\n",
              "      <td>12</td>\n",
              "      <td>0.218182</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>lindork tres sad i wa totally a max fan sytycd</td>\n",
              "      <td>46</td>\n",
              "      <td>10</td>\n",
              "      <td>0.217391</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>-0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>crap i wa counting down the hour until my dad ...</td>\n",
              "      <td>132</td>\n",
              "      <td>30</td>\n",
              "      <td>0.227273</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.474074</td>\n",
              "      <td>-0.235185</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   target                                               text  text_len  words  \\\n",
              "0       0  obama forge his muslim alliance against the ci...       104     22   \n",
              "1       4  had the most spectacular prom ever but now my ...       127     25   \n",
              "2       0  i am overwhelmed today taking a moment to eat ...        55     12   \n",
              "3       0     lindork tres sad i wa totally a max fan sytycd        46     10   \n",
              "4       0  crap i wa counting down the hour until my dad ...       132     30   \n",
              "\n",
              "    density  noun  verb  adj  adv  pron  subjecttivity  polarity  \n",
              "0  0.211538     0     0    0    0     0       0.900000  0.400000  \n",
              "1  0.196850     0     0    0    0     0       0.762500  0.612500  \n",
              "2  0.218182     0     0    0    0     0       0.000000  0.000000  \n",
              "3  0.217391     0     0    0    0     0       0.875000 -0.250000  \n",
              "4  0.227273     0     0    0    0     0       0.474074 -0.235185  "
            ]
          },
          "execution_count": 264,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Feature Construction: Polarity\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "# \n",
        "def get_polarity(text):\n",
        "    return textblob.TextBlob(text).sentiment.polarity\n",
        "\n",
        "df[\"polarity\"]=df.text.apply(get_polarity)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "geXOqgRLdCBL"
      },
      "outputs": [],
      "source": [
        "# Feature Construction: Word Level N-Gram TF-IDF Feature \n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "#\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vec = TfidfVectorizer(ngram_range=(1, 1), max_features=2000)\n",
        "\n",
        "df_char_vect = vec.fit_transform(df.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C77ntLfXdTAa"
      },
      "outputs": [],
      "source": [
        "# Feature Construction: Character Level N-Gram TF-IDF Feature\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "# \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vec = TfidfVectorizer(ngram_range=(2, 2), max_features=2000)\n",
        "\n",
        "df_word_vect = vec.fit_transform(df.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75PUieNPl6j5",
        "outputId": "47fe1a3b-26be-4d92-f375-31a6a49dd669"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[104.        ,  22.        ,   0.21153846, ...,   0.        ,\n",
              "          0.9       ,   0.4       ],\n",
              "       [127.        ,  25.        ,   0.19685039, ...,   0.        ,\n",
              "          0.7625    ,   0.6125    ],\n",
              "       [ 55.        ,  12.        ,   0.21818182, ...,   0.        ,\n",
              "          0.        ,   0.        ],\n",
              "       ...,\n",
              "       [ 56.        ,  13.        ,   0.23214286, ...,   0.        ,\n",
              "          0.56666667,   0.26666667],\n",
              "       [ 40.        ,   8.        ,   0.2       , ...,   0.        ,\n",
              "          0.56785714,   0.49285714],\n",
              "       [ 65.        ,  14.        ,   0.21538462, ...,   0.        ,\n",
              "          0.        ,   0.        ]])"
            ]
          },
          "execution_count": 267,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's prepare the constructed features for modeling\n",
        "# ---\n",
        "#\n",
        "X_metadata = np.array(df.iloc[:, 2:12])\n",
        "X_metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wn_kBCljx6PS",
        "outputId": "c686b00d-e2aa-4da6-ba1f-714bad6ac147"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , ..., 0.        , 0.9       ,\n",
              "        0.4       ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.7625    ,\n",
              "        0.6125    ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.56666667,\n",
              "        0.26666667],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.56785714,\n",
              "        0.49285714],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "execution_count": 268,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# We combine our two tfidf (sparse) matrices and X_metadata\n",
        "# ---\n",
        "#\n",
        "X = scipy.sparse.hstack([df_word_vect, df_char_vect,  X_metadata]).toarray()\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mL7etsSY8cfy",
        "outputId": "a1817e71-cca3-44e9-9f14-c3950a00f5b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 4, 0, ..., 0, 4, 0], dtype=int64)"
            ]
          },
          "execution_count": 269,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Getting our response variable\n",
        "# ---\n",
        "#\n",
        "y = np.array(df.iloc[:, 0])\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_iOhAPnaERN"
      },
      "source": [
        "### 4. Data Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BKyd7Uwl-Vr"
      },
      "source": [
        "During this step, we will use machine learning algorithms to train and test our sentiment analysis models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "533B2cK_Ey3Z"
      },
      "outputs": [],
      "source": [
        "# Splitting our data\n",
        "# ---\n",
        "#\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACi7h1FneII8"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler()\n",
        "\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.fit_transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zx3rCuu6ddht",
        "outputId": "04c88fa7-30e3-431e-fe24-9f0d52f0a282"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=1000)"
            ]
          },
          "execution_count": 272,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Fitting our model\n",
        "# ---\n",
        "#\n",
        "\n",
        "# Importing the algorithms\n",
        "from sklearn.naive_bayes import MultinomialNB \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "nb_classifier = MultinomialNB() \n",
        "lr_classifier = LogisticRegression(max_iter=1000) \n",
        "\n",
        "# Training our model\n",
        "nb_classifier.fit(X_train, y_train) \n",
        "lr_classifier.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grL4WhdTYu5g"
      },
      "outputs": [],
      "source": [
        "# Making predictions\n",
        "# ---\n",
        "#\n",
        "y_predict_nb = nb_classifier.predict(X_test) \n",
        "y_predict_lr = lr_classifier.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyb3cihzdlKX",
        "outputId": "0672fd3f-49aa-4070-8055-d081151ca9d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Naive Bayes Classifier:\n",
            " 0.7475\n",
            "Logistic Regression Classifier: \n",
            " 0.749\n"
          ]
        }
      ],
      "source": [
        "# Evaluating the Models\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# Accuracy scores\n",
        "# ---\n",
        "#\n",
        "print(\"Naive Bayes Classifier:\\n\", accuracy_score(y_test, y_predict_nb)) \n",
        "print(\"Logistic Regression Classifier: \\n\", accuracy_score(y_test, y_predict_lr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obyOpb9uD9IM",
        "outputId": "f5d3564b-268d-4d5c-af31-88a9fc8cd790"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Naive Bayes Classifier: \n",
            " [[782 268]\n",
            " [237 713]]\n",
            "Logistic Regression Classifier: \n",
            " [[829 221]\n",
            " [281 669]]\n"
          ]
        }
      ],
      "source": [
        "# Confusion matrices\n",
        "# ---\n",
        "# \n",
        "print(\"Naive Bayes Classifier: \\n\", confusion_matrix(y_test, y_predict_nb)) \n",
        "print(\"Logistic Regression Classifier: \\n\", confusion_matrix(y_test, y_predict_lr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFdanMG4D6Dn",
        "outputId": "a620aff2-bfb8-42f4-eca3-d4a6f8b32e43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Naive Bayes Classifier: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.74      0.76      1050\n",
            "           4       0.73      0.75      0.74       950\n",
            "\n",
            "    accuracy                           0.75      2000\n",
            "   macro avg       0.75      0.75      0.75      2000\n",
            "weighted avg       0.75      0.75      0.75      2000\n",
            "\n",
            "Logistic Regression Classifier: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.79      0.77      1050\n",
            "           4       0.75      0.70      0.73       950\n",
            "\n",
            "    accuracy                           0.75      2000\n",
            "   macro avg       0.75      0.75      0.75      2000\n",
            "weighted avg       0.75      0.75      0.75      2000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Classification Reports\n",
        "# ---\n",
        "#\n",
        "print(\"Naive Bayes Classifier: \\n\", classification_report(y_test, y_predict_nb)) \n",
        "print(\"Logistic Regression Classifier: \\n\", classification_report(y_test, y_predict_lr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxETCaYyOyHv"
      },
      "source": [
        "**Evaluation our Models**\n",
        "\n",
        "* **Accuracy:** the percentage of texts that were assigned the correct topic.\n",
        "* **Precision:** the percentage of texts the classifier classified correctly out of the total number of texts it predicted for each topic\n",
        "* **Recall:** the percentage of texts the model predicted for each topic out of the total number of texts it should have predicted for that topic.\n",
        "* **F1 Score:** the average of both precision and recall."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbisAqRswA80"
      },
      "source": [
        "To improve our model, we can try perfoming other text processing techniques that would better prepare our data for fitting our model. We can also use different vectorizing techniques, implement other machine learning models and perform hyperparameter tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWiaaYPCnsiC"
      },
      "source": [
        "### 5. Recommendations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3DQO1yFnvx3"
      },
      "source": [
        "Our best model had an accuracy of 73.25% and use it for classifying newer tweets. We can improve this performance by performing hyperparameter tuning and feature engineering methods. "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "enxDwtXPZTpT",
        "85tygFqJZ0Xw",
        "96Uz3PxJZ6E7",
        "YlHYpKxfHRJ4",
        "LWiaaYPCnsiC"
      ],
      "name": "Getting Started with Text Analysis - Project.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}